{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6: A Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture part, we have discussed the foundations of a basic neural network. Here, we will implement the network (based on Tariq Rashid's _Make your own Neural Network_ ) using an object-orientated approach, i.e. create a class ``network``, provide a constructor and methods to check the state of the network, train and query it. We start with two libraries that we will make use of through the entire notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because ``numpy`` does not provide the sigmoid (logistic) activation function we need for our network, we have to implement it by ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have learned in the lecture, our network needs a number of parameters to initialize the weight matrices correctly:\n",
    "\n",
    "- The number of input nodes\n",
    "- The number of hidden nodes\n",
    "- The number of output nodes\n",
    "\n",
    "In addition, next week we will learn about the _learning rate_ that controls the backpropogation process. That's all we need to define the class constructor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __init__(self, iNodes, hNodes, oNodes, lRate):\n",
    "    # Number of input, hidden and output nodes\n",
    "    self.iNodes = iNodes\n",
    "    self.hNodes = hNodes\n",
    "    self.oNodes = oNodes  \n",
    "    # Weight matrices, wih and who, initialized with random numbers that follow a normal distribution\n",
    "    self.wih = np.random.normal(0.0, 0.5, (self.hNodes,self.iNodes))\n",
    "    self.who = np.random.normal(0.0, 0.5, (self.oNodes,self.hNodes))   \n",
    "    # Learning rate (for session 7)\n",
    "    self.lRate = lRate\n",
    "    # Activation function is the sigmoid function\n",
    "    self.actFunc = sigmoid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we won't extend this class too much or create many subclasses, we do not care about access modifiers but keep the code nice and simple. The second method is typically some sort of simple state prompting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def __str__(self):\n",
    "    return f\"Input nodes: {self.iNodes}, Hidden nodes: {self.hNodes}, Output nodes: {self.oNodes}, Learning rate: {self.lRate}, wih matrix shape: {self.wih.shape}, who matrix shape: {self.who.shape}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's final method is a method that feeds an image through the network as shown in the lecture:\n",
    "\n",
    "- Multiply the weight matrix wih (100x784) with the input vector (784x1) \n",
    "- Apply the activation function\n",
    "- Multiply the weight matrix who (10x100) with the vector (100x1) \n",
    "- Apply the activation function\n",
    "\n",
    "The final result is a vector with ten elements where the entries represent the network's prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def query(self, imgArr):\n",
    "    # Transform the image into a vector    \n",
    "    inputs = imgArr.flatten()\n",
    "    # Move signal into hidden layer\n",
    "    hiddenInputs = np.dot(self.wih, inputs)\n",
    "    # Apply the activation function\n",
    "    hiddenOutputs = self.actFunc(hiddenInputs)\n",
    "    # Move signal into output layer\n",
    "    outputs = np.dot(self.who, hiddenOutputs)\n",
    "    # Apply the activation function\n",
    "    prediction = self.actFunc(outputs)\n",
    "    return prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can compile it all into a class ``neuralNetwork``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    def __init__(self, iNodes, hNodes, oNodes, lRate):\n",
    "        # Number of input, hidden and output nodes\n",
    "        self.iNodes = iNodes\n",
    "        self.hNodes = hNodes\n",
    "        self.oNodes = oNodes  \n",
    "        # Weight matrices, wih and who, initialized with random numbers that follow a normal distribution\n",
    "        self.wih = np.random.normal(0.0, 0.5, (self.hNodes,self.iNodes))\n",
    "        self.who = np.random.normal(0.0, 0.5, (self.oNodes,self.hNodes))   \n",
    "        # Learning rate (for session 7)\n",
    "        self.lRate = lRate\n",
    "        # Activation function is the sigmoid function\n",
    "        self.actFunc = sigmoid\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Input nodes: {self.iNodes}, Hidden nodes: {self.hNodes}, Output nodes: {self.oNodes}, Learning rate: {self.lRate}, wih matrix shape: {self.wih.shape}, who matrix shape: {self.who.shape}\"\n",
    "        \n",
    "    def query(self, imgArr):\n",
    "        # Transform the image into a vector    \n",
    "        inputs = imgArr.flatten()\n",
    "        # Move signal into hidden layer\n",
    "        hiddenInputs = np.dot(self.wih, inputs)\n",
    "        # Apply the activation function\n",
    "        hiddenOutputs = self.actFunc(hiddenInputs)\n",
    "        # Move signal into output layer\n",
    "        outputs = np.dot(self.who, hiddenOutputs)\n",
    "        # Apply the activation function\n",
    "        prediction = self.actFunc(outputs)\n",
    "        return prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there is not much we can do yet without training data and the training method (both of which will be covered next week), we can still create a network and check if our class works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iNodes = 784 # The images are 28x28 pixels\n",
    "hNodes = 100 # An educated guess\n",
    "oNodes = 10 # Ten digits\n",
    "\n",
    "lRate = 0.3 # More on that next week\n",
    "\n",
    "testNet = neuralNetwork(iNodes, hNodes, oNodes, lRate) # Create an instance of the network\n",
    "\n",
    "print(testNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrices ``wih`` and ``who`` respresent the network's memory and have been initialized with random numbers. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "wihImg = testNet.wih\n",
    "plt.imshow(wihImg, cmap='Greys', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing but noise ...\n",
    "\n",
    "Finally, we create a noisy test image and feed it into the network to check that the dot products are carried out the way we want it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImg = np.random.normal(0.0, 0.5, (28,28))\n",
    "\n",
    "print(testNet.query(testImg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next week, this output will tell us what the network has detected as input. The first element will represent the probability that the input was a 0, the second element represents the probability that the input was a 1, and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
